# A curated list of papers on **Image-Generation-RL**.



## ğŸ“š Table of Contents
1. [Survey & Overview](#1-survey--overview)
2. [AR Based RL](#2-ar-based-rl)
3. [Diffusion Based RL](#3-diffusion-based-rl)
4. [Video RL](#4-video-rl)
5. [Image Edit RL](#5-image-edit-rl)
6. [Reward Model](#4-reward-model)
7. [Image Generation COT](#5-image-generation-cot)

---

## 1. Survey & Overview

- **todo**  
  *Year:* 2025  [ğŸ“„ Paper]() | [ğŸ’» Code]() | [ğŸŒ Project]()
  
---

## 2. AR Based RL

- **BLIP3o-NEXT**  
  *Year:* 2025  [ğŸ“„ Paper]() | [ğŸ’» Code](https://github.com/JiuhaiChen/BLIP3o) | [ğŸŒ Project](https://jiuhaichen.github.io/BLIP3o-NEXT.github.io/)

- **AR-GRPO: Training Autoregressive Image Generation Models via Reinforcement Learning**  
  *Year:* 2025  [ğŸ“„ Paper](https://arxiv.org/pdf/2508.06924) | [ğŸ’» Code](https://github.com/Kwai-Klear/AR-GRPO) | [ğŸŒ Project]()

- **X-Omni: Reinforcement Learning Makes Discrete Autoregressive Image Generative Models Great Again**  
  *Year:* 2025  [ğŸ“„ Paper](https://arxiv.org/abs/2507.22058) | [ğŸ’» Code](https://github.com/X-Omni-Team/X-Omni) | [ğŸŒ Project](https://x-omni-team.github.io/)

- **T2I-R1:Reinforcing Image Generation with Collaborative Semantic-level and Token-level CoT**  
  *Year:* 2025  [ğŸ“„ Paper](https://arxiv.org/pdf/2505.00703) | [ğŸ’» Code](https://github.com/CaraJ7/T2I-R1)

- **Delving into RL for Image Generation with CoT: A Study on DPO vs. GRPO**  
  *Year:* 2025  [ğŸ“„ Paper](https://arxiv.org/pdf/2505.17017) | [ğŸ’» Code](https://github.com/ZiyuGuo99/Image-Generation-CoT) | [ğŸŒ Project]()

- **Can We Generate Images with CoT? Letâ€™s Verify and Reinforce Image Generation Step by Step**  
  *Year:* 2025  [ğŸ“„ Paper](https://arxiv.org/pdf/2501.13926) | [ğŸ’» Code](https://github.com/ZiyuGuo99/Image-Generation-CoT) | [ğŸŒ Project]()

- **todo**  
  *Year:* 2025  [ğŸ“„ Paper]() | [ğŸ’» Code]() | [ğŸŒ Project]()

---

## 3. Diffusion Based RL

- **Diffusion Model as a Noise-Aware Latent Reward Model for Step-Level Preference Optimization**  
  *Year:* 2025  [ğŸ“„ Paper](https://arxiv.org/abs/2502.01051) | [ğŸ’» Code](https://github.com/Kwai-Kolors/LPO/tree/main) | [ğŸŒ Project]()

- **Flow-GRPO: Training Flow Matching Models via Online RL**  
  *Year:* 2025  [ğŸ“„ Paper](https://arxiv.org/abs/2505.05470) | [ğŸ’» Code](https://github.com/yifan123/flow_grpo) | [ğŸŒ Project](https://gongyeliu.github.io/Flow-GRPO/)

- **DanceGRPO: Unleashing GRPO on Visual Generation**  
  *Year:* 2025  [ğŸ“„ Paper](https://arxiv.org/abs/2505.07818) | [ğŸ’» Code](https://github.com/XueZeyue/DanceGRPO) | [ğŸŒ Project](https://dancegrpo.github.io/)

- **MIXGRPO: UNLOCKING FLOW-BASED GRPO EFFICIENCY WITH MIXED ODE-SDE**  
  *Year:* 2025  [ğŸ“„ Paper](https://arxiv.org/abs/2507.21802) | [ğŸ’» Code](https://github.com/Tencent-Hunyuan/MixGRPO) | [ğŸŒ Project](https://tulvgengenr.github.io/MixGRPO-Project-Page/)

- **TempFlow-GRPO: When Timing Matters for GRPO in Flow Models**  
  *Year:* 2025  [ğŸ“„ Paper](https://www.arxiv.org/abs/2508.04324) | [ğŸ’» Code](https://github.com/Shredded-Pork/TempFlow-GRPO) | [ğŸŒ Project](https://tempflowgrpo.github.io/)

- **Pref-GRPO: Pairwise Preference Reward-based GRPO for Stable Text-to-Image Reinforcement Learning**  
  *Year:* 2025  [ğŸ“„ Paper](https://arxiv.org/pdf/2508.20751) | [ğŸ’» Code](https://github.com/CodeGoat24/Pref-GRPO) | [ğŸŒ Project](https://codegoat24.github.io/UnifiedReward/Pref-GRPO)
  
- **Visual-CoG: Stage-Aware Reinforcement Learning with Chain of Guidance for Text-to-Image Generation**  
  *Year:* 2025  [ğŸ“„ Paper](https://arxiv.org/abs/2508.18032) | [ğŸ’» Code]() | [ğŸŒ Project]()
  
- **Directly Aligning the Full Diffusion Trajectory with Fine-Grained Human Preference**  
  *Year:* 2025  [ğŸ“„ Paper](https://arxiv.org/abs/2509.06942) | [ğŸ’» Code](https://github.com/Tencent-Hunyuan/SRPO) | [ğŸŒ Project](https://tencent.github.io/srpo-project-page/)
  
- **DiffusionNFT: Online Diffusion Reinforcement with Forward Process**  
  *Year:* 2025  [ğŸ“„ Paper](https://arxiv.org/pdf/2509.16117) | [ğŸ’» Code](https://github.com/NVlabs/DiffusionNFT) | [ğŸŒ Project](https://research.nvidia.com/labs/dir/DiffusionNFT/)

- **todo**  
  *Year:* 2025  [ğŸ“„ Paper]() | [ğŸ’» Code]() | [ğŸŒ Project]()

---

## 4. Video RL

- **InfLVG: Reinforce Inference-Time Consistent Long Video Generation with GRPO**  
  *Year:* 2025  [ğŸ“„ Paper](https://arxiv.org/abs/2505.17574) | [ğŸ’» Code](https://github.com/MAPLE-AIGC/InfLVG) | [ğŸŒ Project]()

- **Improving Video Generation with Human Feedback**  
  *Year:* 2025  [ğŸ“„ Paper](https://arxiv.org/abs/2501.13918) | [ğŸ’» Code](https://github.com/KwaiVGI/VideoAlign) | [ğŸŒ Project](https://gongyeliu.github.io/videoalign/)


- **Video Generation Models Are Good Latent Reward Models**  
  *Year:* 2025  [ğŸ“„ Paper](https://arxiv.org/pdf/2511.21541) | [ğŸ’» Code]() | [ğŸŒ Project]()

- **todo**  
  *Year:* 2025  [ğŸ“„ Paper]() | [ğŸ’» Code]() | [ğŸŒ Project]()

  ---

## 5. Image Edit RL

- **Skywork UniPic 2.0: Building Kontext Model with Online RL for Unified Multimodal Model**  
  *Year:* 2025  [ğŸ“„ Paper](https://github.com/SkyworkAI/UniPic/tree/main/UniPic-2) | [ğŸ’» Code](https://github.com/SkyworkAI/UniPic/tree/main/UniPic-2) | [ğŸŒ Project](https://github.com/SkyworkAI/UniPic/tree/main/UniPic-2)

- **OneReward: Unified Mask-Guided Image Generation via Multi-Task Human Preference Learning**  
  *Year:* 2025  [ğŸ“„ Paper](https://arxiv.org/abs/2508.21066) | [ğŸ’» Code]() | [ğŸŒ Project](https://one-reward.github.io/)

- **MM-R1: Unleashing the Power of Unified Multimodal Large Language Models for Personalized Image Generation**  
  *Year:* 2025  [ğŸ“„ Paper](https://arxiv.org/abs/2508.11433) | [ğŸ’» Code]() | [ğŸŒ Project]()

- **UniWorld-V2: Reinforce Image Editing with Diffusion Negative-Aware Finetuning and MLLM Implicit Feedback**  
  *Year:* 2025  [ğŸ“„ Paper](https://arxiv.org/pdf/2510.16888) | [ğŸ’» Code](https://github.com/PKU-YuanGroup/UniWorld-V2) | [ğŸŒ Project]()

- **EditScore: Unlocking Online RL for Image Editing via High-Fidelity Reward Modeling**  
  *Year:* 2025  [ğŸ“„ Paper](https://arxiv.org/abs/2509.23909) | [ğŸ’» Code](https://github.com/VectorSpaceLab/EditScore) | [ğŸŒ Project](https://vectorspacelab.github.io/EditScore/)

- **The Promise of RL for Autoregressive Image Editing**  
  *Year:* 2025  [ğŸ“„ Paper](https://arxiv.org/abs/2508.01119) | [ğŸ’» Code]() | [ğŸŒ Project]()

- **todo**  
  *Year:* 2025  [ğŸ“„ Paper]() | [ğŸ’» Code](https://github.com/mair-lab/EARL) | [ğŸŒ Project]()
  
  ---

## 6. Reward Model

- **RewardDance: Reward Scaling in Visual Generation**  
  *Year:* 2025  [ğŸ“„ Paper](https://arxiv.org/abs/2509.08826) | [ğŸ’» Code]() | [ğŸŒ Project]()

- **todo**  
  *Year:* 2025  [ğŸ“„ Paper]() | [ğŸ’» Code]() | [ğŸŒ Project]()
  
  ---
  
## 7. Image Generation COT

- **Interleaving Reasoning for Better Text-to-Image Generation**  
  *Year:* 2025  [ğŸ“„ Paper](https://arxiv.org/abs/2509.06945) | [ğŸ’» Code](https://github.com/Osilly/Interleaving-Reasoning-Generation) | [ğŸŒ Project]()

- **FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark**  
  *Year:* 2025  [ğŸ“„ Paper](https://arxiv.org/pdf/2509.09680) | [ğŸ’» Code](https://github.com/rongyaofang/prism-bench) | [ğŸŒ Project](https://flux-reason-6m.github.io/)

- **todo**  
  *Year:* 2025  [ğŸ“„ Paper]() | [ğŸ’» Code]() | [ğŸŒ Project]()
  
  
  ---

  
---
